# -*- coding: utf-8 -*-
"""data_preprocessing.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qeyA2hSFYqnf3CJisfPb_H924E-PvTXp
"""

### For more information regarding the code, please consult the notebook files
### final_notebook.ipynb under the section where we build the content recomme-
### dation system

### The reason we preprocess the data beforehand is because the app run slowly.
### Therefore, we have a prebuilt set of recommendation based on the movies
### a user likes.

# Script dependencies
import os
import pandas as pd
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.feature_extraction.text import CountVectorizer

# reading relevant data files
movies_data = pd.read_csv('~/unsupervise_data/movies.csv')
genome_tags = pd.read_csv('~/unsupervise_data/genome_tags.csv')
genome_scores = pd.read_csv(~/unsupervise_data/genome_scores.csv')

# get most relevant ratings
def getMostRelevantTags(n_most_relevant_tags = 50):
    text_data = pd.DataFrame()
    for i, movie_id in enumerate(genome_scores['movieId'].unique()):
        tags_text = {}
        mask = genome_scores['movieId'] == movie_id
        tag_ids = genome_scores[mask].sort_values('relevance', ascending = False).iloc[:n_most_relevant_tags,]['tagId'].to_list()
        tags_list = genome_tags[genome_tags['tagId'].isin(tag_ids)]['tag'].to_list()
        tags_text[movie_id] = ' '.join(tags_list)
        data = pd.DataFrame(tags_text, index = [0]).transpose().rename(columns = {0:'tags'})
        text_data = pd.concat([text_data, data])
        # print(i, movie_id)
    return text_data

# implement the function
text_data = getMostRelevantTags(n_most_relevant_tags = 50)
text_data = text_data.reset_index().rename(columns = {'index':'movieId'})

# merge data to get actual movie titles
text_data = pd.merge(text_data, movies_data[['movieId', 'title']], how = 'left')

# drop duplicated movie titles
text_data.drop_duplicates('title', inplace=True)

# create bag of words model using CountVectoriser
vec = CountVectorizer()
text_matrix = vec.fit_transform(text_data['tags'])

# compute distance and/or similarities and stare them in a dataframe objcet
dist_matrix = cosine_similarity(text_matrix)
dist_matrix = pd.DataFrame(dist_matrix, index = text_data['title'], columns = text_data['title'])
dist_matrix.head(3)

def getRecommendations(neighbors = 10):
    similarity_data = pd.DataFrame()
    for i, movie_title in enumerate(dist_matrix.index):
        sim_data = dist_matrix.loc[movie_title].reset_index()
        sim_data['movie'] = movie_title
        data_renaming = {
                            movie_title:'similarity',
                            'title':'recommendations',
                            'movie':'title'
                        }
        sim_data = (sim_data
                      .rename(columns = data_renaming)
                      .sort_values(by = 'similarity', ascending = False)[1:]
                      .iloc[:10])
        sim_data['rank'] = range(1, len(sim_data) + 1)
        similarity_data = pd.concat([similarity_data, sim_data])
    return similarity_data

# implement function
similarity_data = getRecommendations(neighbors = 10)

# export processed data
similarity_data.to_csv('content_based_similarities.csv')

###############################################################################
###############################################################################
###############################################################################
# example implementation to get recommendations and per the app
movie_list = ['Toy Story (1995)', 'Jumanji (1995)', 'Grumpier Old Men (1995)']
top_n = 10

# to make prediction the user simply quiris the preprocessed data
recommended_movies = list()
for i, movie_title in enumerate(movie_list):
    sim_data = similarity_data[similarity_data['title'] == movie_title]

    similar_movies = sim_data['recommendations'].tolist()
    for movie in similar_movies:
        recommended_movies.append(movie)

# get predictions
pd.Series(recommended_movies).sample(10).tolist()
